import math
import numpy as np
from scipy.optimize import fsolve
import pandas as pd
import os
from itertools import combinations 
# MPA to PSI = x * 145.03773773

from scipy.stats import norm

def pred_W18(tpd:int,vc:float,cd:float,i:float,n:int):
    """
    TPD:int = Trafico promedio diario\n
    vc:float =Distribución por sentido (usalmente 0.5)\n
    cd:float =Carril de diseño (usualmente 1.0 si es de un solo carril por sentido)\n
    i:float =indice de crecimiento \n
    n:int =años de diseño\n
    return -> 365*TPD*VC*CD*(1+i)^n/ln(1+i)\n
    """
    return 365*tpd*vc*cd*(1+i)**n/math.log(1+i)


def predict_pavement_esal(r, so, sn, psi, mr):
    """
    Generate a prediction for Equivalent Single Axle Load (ESAL) based on given parameters.

    Parameters:
    r (float): Reliavility (usually 0.5-0.999)
    so (float): standard error (usually 0.4-0.5 for asphalt, 0.35-0.4 for concrete)
    sn (float): structural number
    psi (float): allowable delta in serviceability index (usually 1.0-3.0)
    mr (float): resilient modulus [PSI]

    Returns:
    float: the predicted ESAL value
    """
    right_side = -norm.ppf(r)*so+9.36*np.log10(sn+1)-0.2+(np.log10(psi/(4.2-1.5))/(0.4+1094/(sn+1)**5.19))+2.32*np.log10(mr)-8.07
    esals = 10**right_side
    return esals

def solve_sn(Reliavility, Standard_Deviation, Delta_PSI, Mr, esal):
    """
    Calculate the required Structural Number (SN) for given parameters.
    
    Parameters:
    Reliavility (float): Reliability level (0.5-0.999)
    Standard_Deviation (float): Standard error (0.4-0.5 for asphalt, 0.35-0.4 for concrete)
    Delta_PSI (float): Allowable serviceability loss (1.0-3.0)
    Mr (float): Resilient modulus [PSI]
    esal (float): Design ESALs
    
    Returns:
    float: Calculated SN value, or None if calculation fails
    """
    def f(sn):
        val = sn[0]
        return predict_pavement_esal(Reliavility,Standard_Deviation,val,Delta_PSI,Mr) - esal
    return fsolve(f,np.array([15]))[0]

"""
Solucionar capa
"""
import random
from copy import deepcopy


class Layer():
    def __init__(self, material_table_row):
        self.name = material_table_row['mat_name']
        self.sn = material_table_row['sn']
        self.cost = material_table_row['cost']
        self.density = material_table_row['density']
        self.unit = material_table_row['unit']
        surface = material_table_row['surface']
        subgrade = material_table_row['subgrade']
        alkaline = material_table_row['alkaline']
        minimum_lift = material_table_row['min']
        self.min_lift = minimum_lift
        self.thickness = minimum_lift
        self.max_lift = material_table_row['max']
        self.cost_per_inch = self.calc_cost_per_inch()
        self.surface_code = 1 if bool(surface) else 0
        self.subgrade_code = 1 if bool(subgrade) else 0
        self.alkaline_code = 1 if bool(alkaline) else 0
        self.cost_per_sn = self.cost_per_inch / self.sn
        return None

    def calc_cost_per_inch(self):
        if self.unit == "ton":
            tonnage = self.density * 27 / 2000
            cost_per_sy = self.cost * tonnage / 36 # in per yd
            return cost_per_sy
        elif self.unit == "cyd":
            cost_per_sy = self.cost / 36
            return cost_per_sy
        elif self.unit == "sqyd":
            return self.cost / self.min_lift
        else:
            return 0.0

class Section(list): # subclass list just for sanity
    def __init__(self, *layers):
        self.totalCost = 0
        super().__init__(*layers)

def make_material_list(material_table:pd.DataFrame)->list[Layer]:
    #TODO make sure Material list is sorted by surface material on top
    return [Layer(material_table.iloc[i]) for i in range(len(material_table))]


def make_trial_section(material_list) -> Section:
    """Depreciated. Use make_possible_sections instead"""
    # select 1-4 materials at random and save to an array
    num_materials: int = np.random.randint(1, 5)
    section = Section()
    for _ in range(num_materials):
        section.append(deepcopy(random.choice(material_list)))
    section.sort(key = lambda l : l.surface_code)
    section.reverse()
    section.sort(key = lambda l : l.subgrade_code)
    return section

def make_possible_sections(material_list:list,num_capas:int):
    """
    ->Return list[Section] \n
    material_list should be sorted by surface_code on top\n
    the list have all the posible combinations without repetition n! / (k! * (n - k)!) when k <= n.\n
    k being num_capas and n being len(material_list). Aditionally removes restrictions such as having one surface, 1 or less alkaline layer, and 1 or less subgrade treatment.\n
    material_list: list of materials generated by make_material_list()\n
    num_capas: The amount of layers of materials to generate the possible sections
    """
    if num_capas <= 0 or num_capas > len(material_list):
        return []
        
    surface_lst = []
    subgrad_lst = []
    alkaline_lst = []
    mat_size = len(material_list)
    
    # Create lists of indices for materials with special properties
    for i in range(mat_size):
        lay = material_list[i]
        if lay.surface_code == 1:
            surface_lst.append(i)
        if lay.subgrade_code == 1:
            subgrad_lst.append(i)
        if lay.alkaline_code == 1:
            alkaline_lst.append(i)
            
    # Generate all possible combinations
    indices = list(combinations(range(mat_size), num_capas))
    if not indices:
        return []
        
    # Filter combinations that don't start with a surface material
    valid_indices = []
    for combo in indices:
        if combo[0] not in surface_lst:
            continue
            
        surface = 0
        alk = 0
        trat_sub = 0
        valid = True
        
        for h in combo:
            if h in surface_lst:
                surface += 1
            if h in alkaline_lst:
                alk += 1
            if h in subgrad_lst:
                trat_sub += 1
                
            # Check constraints
            if alk >= 2 or trat_sub >= 2 or surface >= 2:
                valid = False
                break
                
        if valid and surface == 1:  # Must have exactly one surface layer
            valid_indices.append(combo)
            
    # Create sections from valid combinations
    lst_compl = []
    for ind_sect in valid_indices:
        section = Section()
        for j in ind_sect:
            section.append(deepcopy(material_list[j]))
        lst_compl.append(section)
        
    return lst_compl

def validate_section(section:Section)->bool:
    # no duplicate courses of materials
    names = [l.name for l in section]
    if len(names) != len(set(names)):
        return False
    # must have a surface course
    if section[0].surface_code == 0:
        return False
    # cannot have multiple subgrade treatments
    if sum([l.subgrade_code for l in section]) > 1:
        return False
    # cannot have adjacent alkaline courses
    alk = np.array([l.alkaline_code for l in section])
    alk_roll = np.roll(alk, 1)
    if np.logical_and(alk, alk_roll).any():
        return False
    # thickness must be a positive number
    if any([l.thickness <= 0 for l in section]):
        return False
    # thickness must be achievable within lift size limits
    for l in section:
        if not l.thickness % l.min_lift < l.max_lift-l.min_lift or l.thickness % l.max_lift == 0:
            return False
    return True

def remove_duplicate_sections(section_list):
    result_list = []
    used_combinations = set()
    for section in section_list:
        names = [l.name for l in section]
        names.sort()
        if tuple(names) in used_combinations:
            continue
        result_list.append(section)
        used_combinations.add(tuple(names))
    return result_list


def section_sn(section):
    return sum([l.sn * l.thickness for l in section])


def section_cost(section, grade, embankment_cost, excavation_cost):
    #Se calcula la diferencia de elevación de la subrazante. Si es negativa se multiplica por el costo de excavación, si es positiva por el costo de explanación
    subgrade_elevation = grade - sum([layer.thickness for layer in section])
    earthwork = ((embankment_cost if subgrade_elevation > 0 else excavation_cost)/36)*subgrade_elevation
    section.totalCost = sum([l.cost_per_inch * l.thickness for l in section]) + earthwork
    return section.totalCost


def modify_thickness(section:Section, goal_sn:float,n=0):
    """
    section: Section to modify \n
    goal_sn: Structural number to get\n
    n:int, Number of layers to modify from section (from 1 to n) // 0 all\n
    """
    epsilon = 0.01
    current_sn = section_sn(section)
    if n==0:
        cost_index = [(i,l) for i,l in enumerate(section)]
        cost_index.sort(key=lambda x: x[1].cost_per_sn)
    else:
        lay=section[0:n+1]
        cost_index = [(i,l) for i,l in enumerate(lay)]
        cost_index.sort(key=lambda x: x[1].cost_per_sn)
    increment_size = lambda l: 0.5 if l.min_lift < 2.0 else 1.0
    for _ in range(10):  # this may not benefit from multiple passes
        delta = goal_sn - current_sn+0.1
        if abs(delta) < epsilon:
            break
        for i,_l in cost_index:
            layer:Layer = section[i]
            if layer.min_lift == layer.max_lift:
                continue # pass layers with fixed thickness
            inc = increment_size(layer)
            inc_sn_delta = layer.sn * inc
            adjustment = delta // inc_sn_delta if delta > 0 else np.ceil(delta / inc_sn_delta)
            layer.thickness += inc * adjustment
            if layer.thickness <= layer.min_lift:
                layer.thickness = layer.min_lift
            current_sn = section_sn(section)
            delta = goal_sn - current_sn+0.1#Added value to be over goal_sn in most cases. otherwise it goes near goal_sn
    return section


def solve(material_table, goal_sn, grade=0.0, embankment_cost=0.0, excavation_cost=0.0):
    material_list = make_material_list(material_table)
    """
    sample_population = 5000
    trial_sections = [make_trial_section(material_list) for _ in range(sample_population)]
    unique_sections = remove_duplicate_sections(trial_sections)
    valid_sections = [s for s in unique_sections if validate_section(s)]
    """
    valid_sections = []
    for i in range(1,6):
        valid_sections += make_possible_sections(material_list,i)
    modified_sections = [modify_thickness(s, goal_sn) for s in valid_sections]
    revalidated_sections = [s for s in modified_sections if validate_section(s)]
    revalidated_sections.sort(key=lambda s: section_cost(s, grade, embankment_cost, excavation_cost))
    return revalidated_sections
    
def cargar_materiales(ruta:str)->pd.DataFrame:
    """Carga la lista de materiales a partir de un archivo de texto, devuelve un DATAFRAME"""
    if os.path.exists(ruta):
        tab_ld = pd.read_csv(ruta)
    else:
        #toca crear el archivo
        tab_ld = open(ruta,"a")
        tab_ld.write("mat_name,sn,min,max,density,cost,unit,surface,subgrade,alkaline\n")
        tab_ld.close()
        tab_ld = pd.read_csv(ruta)
    return tab_ld

#TODO SOLVER sobre capas hechas

def resolve(material_table,sect:Section,SN:float,n:int,grade=0.0, embankment_cost=0.0, excavation_cost=0.0):
    """
    sect: Sección a recalcular
    SN: SN a superar
    n: Numero de capas dañadas sobre la sección aka capas a reemplazar
    """
    material_list = make_material_list(material_table)
    prev_sect = Section(sect[n:])
    valid_sections = make_possible_sections(material_list,n)
    for i in range(len(valid_sections)):
        valid_sections[i]+=deepcopy(prev_sect)
    validated_sections = [s for s in valid_sections if validate_section(s)]
    #Aumentar espesor
    modified_sections = [modify_thickness(s, SN,len(s)-len(prev_sect)) for s in validated_sections]    
    revalidated_sections = [s for s in modified_sections if validate_section(s)]
    revalidated_sections.sort(key=lambda s: section_cost(s, grade, embankment_cost, excavation_cost))
    return revalidated_sections
#from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
def make_simulated_transit(TPD=402.39,vc=0.5,cd=1.0,size=5000,n=360,seedint=63442967,mu_annual=0.047,sigma_annual=0.057)->tuple[np.array,np.array]:
    """
    Funtion to generate a bunch of simulated transit\n
    n:int = meses de diseño\n
    seedint = semilla de rng, 0 para no usar semilla.\n
    return tuple of 2D-array like of size*n length of traffic and acumulative traffic at time index (monthly)
    """
    # Monthly growth rates (shape: size x n)
    mu_monthly = mu_annual / 12
    sigma_monthly = sigma_annual / np.sqrt(12)
    if seedint != 0:
        rng = np.random.default_rng(seed=seedint)
        grow_rates = rng.normal(loc=mu_monthly, scale=sigma_monthly, size=(size, n))
    else:
        grow_rates = np.random.normal(loc=mu_monthly,scale=sigma_monthly, size=(size,n))
    initial_monthly_trips = TPD * 365 / 12 * vc * cd
    res = np.zeros((size, n))
    acum = np.zeros((size, n))
    for sim in range(size):
        res[sim, 0] = initial_monthly_trips
        acum[sim, 0] = initial_monthly_trips
        for month in range(1, n):
            # Apply compounded growth: Traffic_t = Traffic_{t-1} * (1 + growth_rate) around the mean (0.39% monthly), with 95% of values in [−2.9%, +3.7%] monthly.
            res[sim, month] = res[sim, month-1] * (1 + grow_rates[sim, month])
            acum[sim, month] = acum[sim, month-1] + res[sim, month]
    # Round to integers as traffic should not be fractional
    res = np.round(res).astype(np.int32)
    acum = np.round(acum).astype(np.int32)
    return res, acum 
#print(make_simulated_transit(100,size=2,n=3))
def calculate_break(arr:np.array,SN_dis,Reliavility,Standard_Deviation,Delta_PSI,Mr)->int:
    """
    arr: array like with acumulative transit\n
    Makes a binary search for the postion when the design fails first\n
    return len(arr)+1 if doesnt fail
    """
    low = 0
    high = len(arr) - 1
    mid = 0
    while low <= high:
        mid = (high + low) // 2
        sn = solve_sn(Reliavility, Standard_Deviation, Delta_PSI, Mr,arr[mid])
        if sn < SN_dis:
            low = mid + 1
        elif sn > SN_dis:
            high = mid - 1
        # means sn IS EQUAL to sn_dis at mid
        else:
            return mid
    # We should reach here meaning mid is the lowest possible without being over SN_dis, so we get the next when it fails 
    #note, it returns len(arr)+1 if dont fail on all the array
    return mid+1

def W18_prediction(TPD=402.39,vc=0.5,cd=1.0,i=0.05,n=30,step=3)->list:
    """Generate the W18 predictions used for the traditional approach in flexible pavement \n
    Additionally creates the additional predictions of W18 to generate an aproach of flexibility in the design with intermediate steps. \n
    TPD:int = Trafico promedio diario\n
    vc:float =Distribución por sentido (usalmente 0.5)\n
    cd:float =Carril de diseño (usualmente 1.0 si es de un solo carril por sentido)\n
    i:float =indice de crecimiento \n
    n:int =años de diseño\n
    return list of pred_w18 for TPD, last is complete
    """
    res = []
    for i in range(1,step+1):
        res.append(pred_W18(TPD,vc,cd,i,n//step*i))
    return res
def W18_linear_regression(arr:np.array)->np.poly1d:
    """\n
    getting a new TPD recalculate with pred_W18
    """
    x= np.arange(len(arr))
    y = arr
    #m, b = np.polyfit(x, y, deg=1)
    #plt.axline(xy1=(0, b), slope=m, label=f'$y = {m:.1f}x {b:+.1f}$')

    coef = np.polyfit(x,y,1)
    poly1d_fn = np.poly1d(coef) 
    #plt.plot(x,y, 'yo', x, poly1d_fn(x), '--k')
    #plt.show()
    return poly1d_fn
def npv(r, arr):
    sum_pv = 0.0
    for i in range(len(arr)):
        sum_pv += arr[i] / ((1 + r) ** i)
    return sum_pv
def evaluate_flexibility(TPD,vc,cd,size,n,rate,sn_design,Reliavility,Standard_Deviation,Delta_PSI,Mr,material_table,org_sect,grade,emb,excv,cost_rb,capas=2,step=3,seedint=63442967,mu_annual=0.047,sigma_annual=0.057)->np.array:
    """
    Funtion to evaluate the design flexibility\n
    size:int = tamaño de muestra aleatoria\n
    n:int = meses de diseño\n
    cost_rb:float = Cost of building redesign (Fixed) \n
    return array of size length of npv (one each for all the simulations)
    """
    res = np.zeros(size)
    random_transit,acumulated = make_simulated_transit(TPD=TPD,vc=vc,cd=cd,size=size,n=n,seedint=seedint,mu_annual=mu_annual,sigma_annual=sigma_annual)
    n_step= n//step
    for sim in range(size):
        random_cost = np.zeros(n+1) #+1 needed to keep the last value in bound of size
        random_cost[0] = org_sect.totalCost + cost_rb
        acumulated_sim:np.array=acumulated[sim,:]
        n_break:int = calculate_break(acumulated_sim,sn_design,Reliavility,Standard_Deviation,Delta_PSI,Mr)
        
        previous=0
        while n_break<=n and previous!=n_break:
            #redesign when break, and add to the cost on period n_break. 
            #TODO
            #Then take the random transit and redesign
            transit_from_simulation= random_transit[sim,:]
            try:
                fun=W18_linear_regression(transit_from_simulation[previous:n_break])
            except np.linalg.LinAlgError:
                print("linear error",sim,"/"+str(size))#624 have a linear error
                break
            except:
                print("other error",sim,"/"+str(size))
                break
            #funtion is the transit for the month. need to acumulate for design
            m, b = fun.coef  # Assuming a linear regression (degree 1) returns two coefficients [m, b]
            
            sum_k = ((n_step - 1) * n_step) / 2
            sum_b = n_step * b
            new_trans = max(m * sum_k + sum_b,0)
            """
            new_trans = 0
            for k in range(n_step):
                new_trans+=max(fun(k),0) 
            """
            sn_rd = solve_sn(Reliavility,Standard_Deviation,Delta_PSI,Mr,new_trans) #Redesign with sn_rd
            
            rd_arr= resolve(material_table,org_sect,sn_rd,capas,grade,emb,excv)
            random_cost[n_break]= rd_arr[0].totalCost + cost_rb#cost of building the redesign 
            previous=n_break  #TODO CHECK+1 (n_break comes with +1 )
            
            #TODO PENSAR BIEN EN INDICES 
            acumulated_sim:np.array=acumulated[sim,:]
            n_break = calculate_break(acumulated_sim-acumulated_sim[previous-1],sn_rd,Reliavility,Standard_Deviation,Delta_PSI,Mr)
        #calculate NPV from redesign until n
        res[sim]= npv(rate,random_cost)
    return res 
#print(npv(0.05,make_simulated_transit(100,size=2,n=3)[0]))